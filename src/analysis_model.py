# analysis_model.py
import sys
import datetime
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

DATA_PATH = "data/clean_abandonments.csv"

# ---------- ì½˜ì†” ì¶œë ¥ + íŒŒì¼ ë¡œê·¸ ë™ì‹œ ì €ì¥ ì„¤ì • ----------
log_filename = f"analysis_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
log_file = open(log_filename, "w", encoding="utf-8")

class Tee:
    def __init__(self, *streams):
        self.streams = streams
    def write(self, data):
        for s in self.streams:
            s.write(data)
    def flush(self):
        for s in self.streams:
            s.flush()

sys.stdout = Tee(sys.stdout, log_file)
# -------------------------------------------------------


def load_data(path: str = DATA_PATH) -> pd.DataFrame:
    print("ğŸ“¥ ë°ì´í„° ë¡œë“œ ì¤‘:", path)
    ab = pd.read_csv(path)
    print(" - ìœ ê¸°ë™ë¬¼ ë°ì´í„° shape:", ab.shape)
    return ab


# 4-1. ê¸°ë³¸ ë¶„í¬ / íŒ¨í„´ ë¶„ì„ ---------------------------------------------

def analyze_basic_patterns(ab: pd.DataFrame) -> None:
    print("\n===== [4-1] ì²˜ë¦¬ê²°ê³¼ ë¶„í¬ (processState ë¹„ìœ¨) =====")
    print(ab["processState"].value_counts(normalize=True).round(4))

    print("\n===== [4-1] ì¢…(species) ë¶„í¬ =====")
    print(ab["species"].value_counts().head(10))

    print("\n===== [4-1] ì„±ë³„(sex) ë¶„í¬ =====")
    print(ab["sex"].value_counts(dropna=False))

    print("\n===== [4-1] ì¤‘ì„±í™”(neuter) ì—¬ë¶€ ë¶„í¬ =====")
    print(ab["neuter"].value_counts(dropna=False))

    print("\n===== [4-1] ì—°ë ¹(age) ê¸°ì´ˆ í†µê³„ =====")
    print(ab["age"].describe())


# 4-2. ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• (RandomForest ê¸°ë°˜) --------------------------------

def build_and_evaluate_model(ab: pd.DataFrame) -> None:
    print("\n===== [4-2] ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• (processState ì˜ˆì¸¡) =====")

    # 10% ìƒ˜í”Œë§ (57ë§Œ â†’ 5.7ë§Œ)
    print("\n10% ìƒ˜í”Œë§ ì ìš© ì¤‘... (ëª¨ë¸ í•™ìŠµ ì „ìš©)")
    ab_sample = ab.sample(frac=0.1, random_state=42)
    print(" - ìƒ˜í”Œë§ í›„ ë°ì´í„° shape:", ab_sample.shape)

    features = [
        "species", "breed", "sex", "neuter",
        "age", "weight", "month", "season",
        "weekday", "sido", "sigungu",
    ]
    target = "processState"

    df_model = ab_sample[features + [target]].dropna(subset=[target]).copy()

    # ìˆ˜ì¹˜í˜• ê²°ì¸¡ì¹˜ ë³´ì •
    df_model["weight"] = df_model["weight"].fillna(df_model["weight"].mean())
    df_model["age"] = df_model["age"].fillna(df_model["age"].median())

    X = df_model[features].copy()
    y = df_model[target].copy()

    categorical_features = [
        "species", "breed", "sex", "neuter",
        "season", "weekday", "sido", "sigungu",
    ]
    numeric_features = ["age", "weight", "month"]

    preprocess = ColumnTransformer(
        transformers=[
            ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features),
            ("num", "passthrough", numeric_features),
        ]
    )

    model = Pipeline(steps=[
        ("preprocess", preprocess),
        ("clf", RandomForestClassifier(
            n_estimators=200,
            random_state=42,
            n_jobs=-1,
        )),
    ])

    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2,
        random_state=42,
        stratify=y,
    )

    print(" - í•™ìŠµ ë°ì´í„° í¬ê¸°:", X_train.shape)
    print(" - í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°:", X_test.shape)

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    print("\n[ëª¨ë¸ ì •í™•ë„] accuracy:", round(acc, 4))
    print("\n[í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì§€í‘œ] classification_report:")
    print(classification_report(y_test, y_pred, zero_division=0))


# 4-3. ì‹œê³„ì—´ ë¶„ì„ (Time Series) ----------------------------------------

def analyze_time_series(ab: pd.DataFrame) -> None:
    print("\n===== [4-3] ì‹œê³„ì—´ ë¶„ì„ (Time Series) =====")

    if "year" in ab.columns:
        yearly = ab.groupby("year")["uid"].count()
        print("\n[ì—°ë„ë³„ ìœ ê¸°ë™ë¬¼ ë°œìƒ ê±´ìˆ˜]")
        print(yearly)

        year_state = ab.groupby(["year", "processState"])["uid"].count()
        print("\n[ì—°ë„ Ã— ì²˜ë¦¬ê²°ê³¼ ë°œìƒ ê±´ìˆ˜]")
        print(year_state.head(20))
    else:
        print(" - year ì»¬ëŸ¼ì´ ì—†ì–´ ì—°ë„ë³„ ë¶„ì„ì€ ìƒëµí•©ë‹ˆë‹¤.")

    monthly = ab.groupby("month")["uid"].count()
    print("\n[ì›”ë³„ ìœ ê¸°ë™ë¬¼ ë°œìƒ ê±´ìˆ˜]")
    print(monthly)

    month_state = ab.groupby(["month", "processState"])["uid"].count()
    print("\n[ì›”ë³„ Ã— ì²˜ë¦¬ê²°ê³¼ ë°œìƒ ê±´ìˆ˜]")
    print(month_state.head(20))


# 4-4. ì§€ì—­ ê¸°ë°˜ ë¶„ì„ (Spatial Analysis) --------------------------------

def analyze_spatial(ab: pd.DataFrame) -> None:
    print("\n===== [4-4] ì§€ì—­ ê¸°ë°˜ ë¶„ì„ (Spatial Analysis) =====")

    print("\n[ì‹œë„ë³„ ìœ ê¸°ë™ë¬¼ ë°œìƒ ê±´ìˆ˜ TOP 10]")
    sido_cnt = ab.groupby("sido")["uid"].count().sort_values(ascending=False)
    print(sido_cnt.head(10))

    print("\n[ì‹œêµ°êµ¬ë³„ ìœ ê¸°ë™ë¬¼ ë°œìƒ ê±´ìˆ˜ TOP 20]")
    sigungu_cnt = ab.groupby("sigungu")["uid"].count().sort_values(ascending=False)
    print(sigungu_cnt.head(20))

    print("\n[ì‹œë„ Ã— ì²˜ë¦¬ê²°ê³¼ êµì°¨í‘œ]")
    crosstab_sido_state = pd.crosstab(ab["sido"], ab["processState"])
    print(crosstab_sido_state.head(10))


# 4-5. ë‹¤ë³€ìˆ˜ ìƒê´€ê´€ê³„ ë¶„ì„ ---------------------------------------------

def analyze_correlations(ab: pd.DataFrame) -> None:
    print("\n===== [4-5] ë‹¤ë³€ìˆ˜ ìƒê´€ê´€ê³„ ë¶„ì„ =====")

    num_cols = ["age", "weight", "month"]
    available = [c for c in num_cols if c in ab.columns]

    if available:
        print("\n[ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìƒê´€ê³„ìˆ˜]")
        print(ab[available].corr().round(3))
    else:
        print(" - ìƒê´€ê³„ìˆ˜ ê³„ì‚° ê°€ëŠ¥í•œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    print("\n[ì„±ë³„(sex) Ã— ì²˜ë¦¬ê²°ê³¼(processState) êµì°¨í‘œ]")
    print(pd.crosstab(ab["sex"], ab["processState"]))

    print("\n[ì¤‘ì„±í™”(neuter) Ã— ì²˜ë¦¬ê²°ê³¼(processState) êµì°¨í‘œ]")
    print(pd.crosstab(ab["neuter"], ab["processState"]))

    print("\n[ì¢…(species) Ã— ê³„ì ˆ(season) êµì°¨í‘œ]")
    print(pd.crosstab(ab["species"], ab["season"]))


# ë©”ì¸ ì‹¤í–‰ --------------------------------------------------------------

def main():
    ab = load_data()

    analyze_basic_patterns(ab)      # 4-1
    build_and_evaluate_model(ab)    # 4-2 (ìƒ˜í”Œë§ ì ìš©)
    analyze_time_series(ab)         # 4-3
    analyze_spatial(ab)             # 4-4
    analyze_correlations(ab)        # 4-5

    # ë¡œê·¸ íŒŒì¼ ë‹«ê¸°
    log_file.close()


if __name__ == "__main__":
    main()
